{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_text_generation_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kvamsi7/Text-Generation/blob/main/project_text_generation_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZNHqp5lnxz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "521352c4-d679-4b91-fcec-2b0a0b086037"
      },
      "source": [
        "#download the data and save it to poem.txt\n",
        "!wget https://www.gutenberg.org/files/1661/1661-0.txt -O book.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-04 08:38:48--  https://www.gutenberg.org/files/1661/1661-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607430 (593K) [text/plain]\n",
            "Saving to: ‘book.txt’\n",
            "\n",
            "book.txt            100%[===================>] 593.19K  1.16MB/s    in 0.5s    \n",
            "\n",
            "2021-08-04 08:38:49 (1.16 MB/s) - ‘book.txt’ saved [607430/607430]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHLcaBBEoLRd"
      },
      "source": [
        "#read the file in text string\n",
        "text = open('book.txt', 'r', encoding='utf-8').read()\n",
        "text = text.lower()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbUq1oKCotPP"
      },
      "source": [
        "#create list of sentences\n",
        "sentences = text.split('\\n')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS0-TSEE5RZL"
      },
      "source": [
        "#import dependencies to preprocess the text data and making sequences\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60_eT7er5qhQ"
      },
      "source": [
        "#initialize the tokenizer, which can work char by char\n",
        "tokenizer = Tokenizer(oov_token='<UNK>')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ-PNcaNAeCW"
      },
      "source": [
        "tokenizer.fit_on_texts(sentences)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qu1rTY7NCxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db04c069-d8e3-4ad6-88d2-a58377a15e05"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijgFGdsTGzPw"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaFyCfGE-vSi"
      },
      "source": [
        "input_sequences = []\n",
        "for sequence in sequences:\n",
        "  for i in range(1, len(sequence)):\n",
        "    n_gram_sequence = sequence[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5RZLLmsAipB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8515fba2-7626-481a-be13-16a7c9380e83"
      },
      "source": [
        "print(input_sequences[0], input_sequences[1], input_sequences[2], input_sequences[3])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4775, 145] [4775, 145, 132] [4775, 145, 132, 886] [4775, 145, 132, 886, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3mHT6TUBApU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65c401aa-cbee-4c20-8900-b2acb78f85fb"
      },
      "source": [
        "#find the maximum length among sequences\n",
        "max_seq_len = max([len(seq) for seq in input_sequences])\n",
        "max_seq_len"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJXOYpf3nI0H"
      },
      "source": [
        "#we will keep the last value of the sequence as our target label and all values before that as input to sequence model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8mnnT6nBi5K"
      },
      "source": [
        "#pad the sequences to ensure that they are all of same length\n",
        "padded_sequences = pad_sequences(input_sequences, maxlen = max_seq_len)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpvirsLgWPoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f432dab-ec60-4c4b-8491-9bcaf1122cbe"
      },
      "source": [
        "print(padded_sequences[0], padded_sequences[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0 4775  145] [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0 4775  145  132]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYhboOBWCLb3"
      },
      "source": [
        "import numpy as np\n",
        "padded_sequences = np.array(padded_sequences)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BW2NjBcCjLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f12531-e219-42bb-ff5d-2161af8cbc9b"
      },
      "source": [
        "print(len(padded_sequences[0]))\n",
        "print(len(padded_sequences[1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdvK9urMCZXC"
      },
      "source": [
        "#prepare training sequences and labels\n",
        "x = padded_sequences[:, : -1]\n",
        "labels = padded_sequences[:, -1]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBMmN6-qMqKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c90ac8-24a7-4215-fdce-bff0859ef1b3"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101575,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvrPC8n5Dw61"
      },
      "source": [
        "#to one hot encode the labels\n",
        "y = tf.keras.utils.to_categorical(labels, num_classes=vocab_size)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncT36ipmJaqR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd1fad29-35ea-40ac-b503-5d1da7f6e3e2"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101575, 19)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIdAL56IcTXW"
      },
      "source": [
        "#x = x.reshape(x.shape[0], x.shape[1], 1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSSjSqj-JXrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf547344-4994-4af0-89c6-9a19b2ee7341"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101575, 8915)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6H2aOeJGIfG"
      },
      "source": [
        "#import dependencies for defining the model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKJVkDw8GxCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a45197-c510-455f-aa47-5c813d07cadc"
      },
      "source": [
        "#define and compile the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, input_length=max_seq_len-1))\n",
        "model.add(Bidirectional(LSTM(256)))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "adam = Adam(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 19, 100)           891500    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 512)               731136    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8915)              4573395   \n",
            "=================================================================\n",
            "Total params: 6,196,031\n",
            "Trainable params: 6,196,031\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_L_wdid2YzQ"
      },
      "source": [
        "#initialize the callback for early stopping the training if there is not at least 1% improvement in the accuracy \n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor = 'acc', min_delta=0.01)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAyKsdQtHxkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4736f8d-7163-45ea-b9ba-b20235b554f3"
      },
      "source": [
        "model.fit(x, y, epochs=50, verbose=1, batch_size=150, callbacks=[es])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 5.1395 - acc: 0.1532\n",
            "Epoch 2/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 4.9816 - acc: 0.1668\n",
            "Epoch 3/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 4.4346 - acc: 0.1939\n",
            "Epoch 4/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 3.8445 - acc: 0.2337\n",
            "Epoch 5/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 3.4735 - acc: 0.2703\n",
            "Epoch 6/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 3.1869 - acc: 0.3048\n",
            "Epoch 7/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.9494 - acc: 0.3373\n",
            "Epoch 8/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.7764 - acc: 0.3632\n",
            "Epoch 9/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.6354 - acc: 0.3849\n",
            "Epoch 10/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.5211 - acc: 0.4040\n",
            "Epoch 11/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.4198 - acc: 0.4199\n",
            "Epoch 12/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.3470 - acc: 0.4333\n",
            "Epoch 13/50\n",
            "678/678 [==============================] - 28s 42ms/step - loss: 2.3100 - acc: 0.4393\n",
            "Epoch 14/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.2505 - acc: 0.4492\n",
            "Epoch 15/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.2210 - acc: 0.4543\n",
            "Epoch 16/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.1605 - acc: 0.4653\n",
            "Epoch 17/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.1393 - acc: 0.4699\n",
            "Epoch 18/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.1445 - acc: 0.4691\n",
            "Epoch 19/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.1263 - acc: 0.4711\n",
            "Epoch 20/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.0995 - acc: 0.4764\n",
            "Epoch 21/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.1016 - acc: 0.4737\n",
            "Epoch 22/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.0946 - acc: 0.4754\n",
            "Epoch 23/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.0745 - acc: 0.4826\n",
            "Epoch 24/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.0594 - acc: 0.4852\n",
            "Epoch 25/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.0555 - acc: 0.4859\n",
            "Epoch 26/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0498 - acc: 0.4848\n",
            "Epoch 27/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0706 - acc: 0.4830\n",
            "Epoch 28/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0454 - acc: 0.4866\n",
            "Epoch 29/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.0637 - acc: 0.4836\n",
            "Epoch 30/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0775 - acc: 0.4808\n",
            "Epoch 31/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0614 - acc: 0.4832\n",
            "Epoch 32/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0705 - acc: 0.4831\n",
            "Epoch 33/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0527 - acc: 0.4839\n",
            "Epoch 34/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0441 - acc: 0.4856\n",
            "Epoch 35/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0494 - acc: 0.4867\n",
            "Epoch 36/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0616 - acc: 0.4819\n",
            "Epoch 37/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0616 - acc: 0.4838\n",
            "Epoch 38/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0527 - acc: 0.4847\n",
            "Epoch 39/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0518 - acc: 0.4843\n",
            "Epoch 40/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0717 - acc: 0.4816\n",
            "Epoch 41/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0853 - acc: 0.4785\n",
            "Epoch 42/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0936 - acc: 0.4767\n",
            "Epoch 43/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.0722 - acc: 0.4808\n",
            "Epoch 44/50\n",
            "678/678 [==============================] - 27s 40ms/step - loss: 2.0924 - acc: 0.4772\n",
            "Epoch 45/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.1013 - acc: 0.4763\n",
            "Epoch 46/50\n",
            "678/678 [==============================] - 29s 43ms/step - loss: 2.0825 - acc: 0.4795\n",
            "Epoch 47/50\n",
            "678/678 [==============================] - 29s 42ms/step - loss: 2.0918 - acc: 0.4770\n",
            "Epoch 48/50\n",
            "678/678 [==============================] - 28s 42ms/step - loss: 2.1456 - acc: 0.4692\n",
            "Epoch 49/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.1097 - acc: 0.4741\n",
            "Epoch 50/50\n",
            "678/678 [==============================] - 28s 41ms/step - loss: 2.0826 - acc: 0.4792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f617af81e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKmppR6VRUwf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efeb94d1-7071-4fda-dab9-c25a65d04741"
      },
      "source": [
        "#Time to become storyteller!\n",
        "seed_text = \"I could not help laughing at the ease with which he explained his process of deduction\"          \n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "  sequence = tokenizer.texts_to_sequences([seed_text])\n",
        "  padded = pad_sequences(sequence, maxlen=max_seq_len-1)\n",
        "  predicted = model.predict_classes(padded, verbose=0)\n",
        "  output_word = ''\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += ' ' + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "I could not help laughing at the ease with which he explained his process of deduction ” i asked the house and i was a little and of the door you have the man of the door of the little man of the door of the door of the door of the door of the and of the door of the door and i am the very time and i have the man of the door of the door of the door of the door of the door of the door of the door and i am the very time and i have the man of the door of the door of the door of the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx1NNNxMILmW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "8fe5f8c4-be01-47b7-fffb-f3e2e59d1db7"
      },
      "source": [
        "#let's look at how loss and accuracy changed while training\n",
        "import matplotlib.pyplot as plt\n",
        "history = model.history\n",
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-b860c0722ef3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    }
  ]
}